{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets import EMNIST\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    lambda img: torchvision.transforms.functional.rotate(img, -90),\n",
    "    lambda img: torchvision.transforms.functional.hflip(img),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = EMNIST(\n",
    "    root='data',\n",
    "    split='letters',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "test_data = EMNIST(\n",
    "    root='data',\n",
    "    split='letters',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124800\n",
      "20800\n",
      "['N/A', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Amount of classes: 27\n",
      "Image size: [C,W,H] = torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(train_data.classes)\n",
    "n_classes = len(train_data.classes)\n",
    "print(f\"Amount of classes: {n_classes}\")\n",
    "print(f\"Image size: [C,W,H] = {train_data[0][0].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAACZCAYAAABHTieHAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAFJJJREFUeJzt3WuwVWX9B/BFKJQgBCQOGkIEOQgo+aJJHQTHy6hADL6wi1iZNU2XacaZZkzLbNJelNFYmDZTbxzShppJLDCa8oJW0EyagjcGlUuQcpObKFf5v2rGtX6/v2wO5+Hsc87n8+75znP2eWCvs/Z+Zq3f+vU5fPjw4QoAAKCTvaerFwAAAPRMNhsAAEARNhsAAEARNhsAAEARNhsAAEARNhsAAEARNhsAAEARNhsAAEARJ7Q6sU+fPiXXQTd1vHpCOv7IHM+epI5BMs6BdCXHH12p1ePPlQ0AAKAImw0AAKAImw0AAKAImw0AAKCIlgvEeXd9+/YNWbNw5u233z5eywGAbi8rTD6eD4agd3P8dQ5XNgAAgCJsNgAAgCJsNgAAgCJsNgAAgCIUiHfA0KFDQ/bpT386ZOvXr6+NFy1aFOYoNAKgN2oW344aNSrMybKlS5cWWxO913vf+96QXXfddSH705/+FLK1a9eWWFKP4coGAABQhM0GAABQhM0GAABQhJqNDhg9enTIvvGNb4SseT/qsmXLwpytW7d22rqA9qMpFOSa9Ri/+c1vwpxm7WNVVdUTTzwRMk1zOVannXZayLKajX79+oXsrrvuCtmhQ4c6Z2E9gCsbAABAETYbAABAETYbAABAETYbAABAEQrEj+B973tfyGbOnBmykSNHhuyEE+r/vR/84AfDHAXi0LM0HyAxduzYMCcrcN23b1+pJUFban5GDhw4MMx54YUXQqYYnBJmz54dsjFjxoTs0UcfDZli8HfnygYAAFCEzQYAAFCEzQYAAFCEzQYAAFCEAvF3eM974t7r8ssvD9lXvvKVkGWF5AcOHOichQFtqVngWlVV9dvf/rY2njx5cphz0003heynP/1pyA4ePNjxxUGbGzRo0BHn7Ny58zishN6ob9++tfF5550X5mzfvj1kq1evLramnsqVDQAAoAibDQAAoAibDQAAoAibDQAAoAgF4u+QFYhPmjQpZEOGDAnZ4cOHQ7Z+/fraeMOGDcewOqA7GDx4cG2cFZFnhYjz588P2ebNmztvYdCFsr+D6dOnH/HnHnrooRLLgWrChAm18WWXXRbmLFmyJGT79u0rtqaeypUNAACgCJsNAACgCJsNAACgCDUb73DiiSeGLGs6lNV2HDp0KGQPPvhgbbxt27ZjWB2dJXufTzvttJD16dOnNt60aVOYk927+fbbbx/D6tpT//79a+MRI0a09HOvvfZayPbu3dspa2oH2Xu9cuXK2vjDH/5wmHPFFVeE7Nprrw3Z3Llzj7iGZmOqqor3IldVVV188cUha57fdu3aFebcc889IetJ7yFdJ/ssbco+W+FoZTVDzXPinj17wpwFCxaErCd+xpfmygYAAFCEzQYAAFCEzQYAAFCEzQYAAFCEAvF3yIpep02bFrKsIPPAgQMh27lzZ22cNf7j+Gs2XauqqpoxY0bImgVlTzzxRJizdu3akO3evTtk2fHRrrLj+/TTT6+NZ86cGeY0C+qrqqoeeeSRkK1atSpk+/fvr427y99KVii4bNmy2jgrBm8W3FdV3uiv+V4MGzYszJkyZUrIbrnllpCNGzcuZM2HJWQPPHj99ddDtnjx4pBt3bo1ZO0gOy5HjRoVsmZxfPbvpuOyAt1mgXhWMJ6dj+BoZeeB5neBv//972FO9rnP0XNlAwAAKMJmAwAAKMJmAwAAKMJmAwAAKKJXF4g3C9ZmzZoV5owfP76l13rxxRdDtnDhwg6ti86TFRxmBbU333xzyJrdlV999dUw52c/+1nIFi1aFLKskLwdDB8+PGSTJk0K2de//vXa+JJLLmnp9bOu2N/97ndDtnz58tp427ZtLb1+O5o/f35tfP7554c5s2fPDtmFF14YsmYh/q233hrmTJw4saV1ZQXPO3bsqI2HDBkS5vzyl78MWVYg/qlPfSpkWcF5SVnh/VVXXRWyu+++O2Q/+clPauPbbrut8xbWgw0dOjRkc+bMCdlnP/vZkI0ePbo2HjBgQJhzxx13hOzJJ58MWfawhmeffbY2XrNmTZjzgQ98IGRPP/10yNr1AQi0pvmQk6qqqunTp9fG2We3B0V0Dlc2AACAImw2AACAImw2AACAImw2AACAInp1gXize25WQNSvX7+QHTp0KGR/+ctfQrZ69epjWB2dISsYzQp2TznllJA1HyDQLGasqryjc9Yptys0O6ZmXZOvv/76kH384x8P2dSpU2vj7N+Ydf0++eSTj7jOnmb79u218YoVK8KcrEA8O5bmzZtXG2cF/QcPHgxZVui4YMGCkK1cubI2zrqY33PPPSHLHhBw5plnhiz7t5c0YsSIkN1www0hywqR2+XvtrvJCsSz88pZZ50VsmZ38KzL85VXXhmyyy+/PGTZ+af5AIQ33njjiGuoqqqaO3duyJoPFci+B9C+svNrduxShisbAABAETYbAABAETYbAABAETYbAABAEb26Iu7UU0+tjadNmxbmZMVjb731Vsg2btwYsgMHDnR8cXRIs2P4wIEDw5wPfehDR/y57iY7TpvF8RdccEGYM2PGjJBlD0poFs9mxZF79+4N2T//+c+QPffccyHLCje7q+b/TVYknXU7zt7D5nuR/dySJUtC9rWvfS1kWVf25lo3bNgQ5mQd37OHDVx88cUhe/7552vjrJi9M2VF3oMHDw5Z9vc+YcKEI87J/v97u6zDctZ1/qKLLgrZlClTauOsm3er70NWXD5kyJDaOPs8yD67s2Jzuo/sgS833nhjyM4444zaeNeuXcXW1Nt1729YAABA27LZAAAAirDZAAAAiujVNRvNe9pbbUC2adOmkD3++OMhK31/MlHzPR05cmSYM3ny5JC1UrOR1eBk93iWft+zRpPNe5+rKjbn+8IXvhDmZI0Ks3uf9+3bVxv/+c9/DnP+/e9/h+zee+8N2bp160LWk+6Rbt5P/re//S3MyeonsvuMm7J6scceeyxkmzdvPuJrtfr6Tz31VMia9zpXVV7r02yc2i7nxOzvvVmHomajNVnNxl133RWyrI7j5ptvro1vuummMOc///lPyKZPnx6yVo6tbE72ed4831WV9747yeq0Jk2aFLLm587SpUvDnHY5Z3V3rmwAAABF2GwAAABF2GwAAABF2GwAAABF9OoC8bPOOqs2fv/739/Sz2WFwjt37uyMJXGMmo0ap06dGuaMGDGiQ6/d6oMBsnkdlTW5uuaaa0I2c+bMkE2cOLE2Hj58eJiTFWZnxZH/+te/auNbb701zHn55ZdD1pOa9XXU9u3bQ5YVvWYF4s2i1EceeSTMefDBB49hde/++6qqqlauXBmy7HjLmqI2/x7Xrl3b4bW1IisMbRapV1Ve9NksDlUY2rmyRqA7duyojbNzz0svvRSy1atXt/T69E7ZQ2CGDh0asubDDbLzciZ7eEQrTVmzpqPZeSZrrtrdz0eubAAAAEXYbAAAAEXYbAAAAEXYbAAAAEX06gLxs88+uzYeMmRISz+nk2j7ahZgDRgw4Ihzqirvmt0sns4eDJAVQHe0kKuVArOqqqpZs2aFLOuOOmjQoCP+zqwg89VXXw3ZkiVLauONGzeGOVn3afLjYfHixSFrno8yWTfv9evXd2xhLfrjH/8YsmuvvTZkI0eODNlHP/rR2rgzC8SzIs0bb7yxpXXt378/ZNkxTefJ/g6aD9jIOt9nD8nIztf0Ttl54Oqrrw5Z9gCgRYsW1cbZwzyy42/KlCkhy87fM2bMqI1PPvnkMGf37t0hmz9/fsjuv//+2njr1q1hTjtzZQMAACjCZgMAACjCZgMAACjCZgMAACiiVxeIN4t1sqKzrIB2+fLlIWt2QqVrNDu5P/fcc2FO9l5l3ZtbkR0zWQF6VpzWLFwdM2ZMmDNnzpyQnXfeeSHr37//uy2zqqq8gPv3v/99yJrF4FVVVQ888EBt/Oabbx7x9/H/604Pmci66j799NMhy7qKN4smm8fRsciO+XPPPTdk2YMXsocgNDuIU17zfJ0VkQ8cOPB4LYduaNiwYSGbOnVqyLLP6mYn+m9/+9thTvYwjFNPPTVkmzZtCtnChQtr4z179oQ5EyZMCNn3v//9kF100UW18fXXXx/mNDuitxNXNgAAgCJsNgAAgCJsNgAAgCJsNgAAgCJ6TYF4VrQ7bdq02jgrJFy3bl3Ifv7zn4ds27ZtHV8cnabZAfSZZ54Jc7L3tJUutVkh2le/+tWQNYseq6qqxo8fH7LJkyfXxll30aFDh4YsO04PHToUsr1799bGzWK1qqqq733veyH773//GzLdwbtGsztu1il+yJAhIduyZUunrSHrqrty5cqQzZ49O2TNovEf/OAHYU5WFNyKrDN4lmWyQvUXXnihQ+ug45rvfdbFfdy4cSHLHrjR3Toq0zkGDx4csuz4yDqNX3rppbXxRz7ykZZ+59y5c0P2hz/8IWTNc0p2rsvO39nrN8+l2XcWBeIAAECvY7MBAAAUYbMBAAAU0WtqNrL74pr392aNtrLmVdk9/4cPH+744ug0zfdw165dYU7W6C+7F77ZNCyrqZgxY0bIsvsys/tKm8dkdk9plmWvn92r2Wxc9tBDD4U5WX1Gs9aDrtN8/7MGUNmx1Zk1G5ns7yrTPMdmNUibN29u6bWatUrNhoHZnKrKz+v/+Mc/QpY1cKWsZo1G1szshz/8YciyBm3wP9nxkX2WNusm77///jDnxz/+cchWrFgRso5+B8zOf7fffnvIPvaxj9XG06dPD3NeeeWVkHW0Jq6zubIBAAAUYbMBAAAUYbMBAAAUYbMBAAAU0WsKxAcMGBCyk046qTbOCgmzYuIdO3Z02rroXM33MGu2eOedd4bsnHPOCdnYsWNr44EDB4Y5o0ePProFvousMV9W8JU1JMsKXl9++eXaeNWqVWGOotiukZ1rWikwzIocS8sKDB9++OGQvfnmmyFrFoRfccUVYc7vfve7ll5r1KhRtfE111wT5mT/PwcOHAhZdl7P3hPKar43Pls5WtkDMlq1du3a2jhrcpt9Bpd+IFD2XaAp+z7SzlzZAAAAirDZAAAAirDZAAAAirDZAAAAiug1BeJZMc2GDRtq46zLeNZBvJXiHdpDVsj14osvhiwrDGt2F505c2aYM2jQoA6vrdmFec2aNWHOfffdF7K//vWvIXvrrbdCpuC1fWXd3K+77rqQdeYDCDrTypUrQ5Z12v3mN79ZG//iF78Ic2644YaQzZs3L2Sf+MQnauMrr7wyzMn+3p9//vmQrV+/PmQcf82C/okTJ4Y5zQcDVFVeFLxly5bOWxhtacyYMSH7zne+E7ITTohfbbMHXTQ7hndFMXim+d2jquJ32OwzpF26hWdc2QAAAIqw2QAAAIqw2QAAAIqw2QAAAIrokQXiWXHQpZdeGrJx48bVxi+99FKYo9Nsz7N///6QLV++PGTN7qK7d+8OczqzQLz5+6qqqpYtWxayrLtyVxSx0XE7d+4MWSvd3E888cSQHUsH3Y7Kjrd77703ZGPHjq2NP/OZz4Q5Z599dsjuuOOOkJ100km1cd++fcOczZs3h+zOO+8M2d69e0NG19uzZ0/Isg7w9E6zZs0K2SWXXBKyPn36hKz5MIKqqqrzzz+/Ns4eRpB9LndUds4aNmxYyObMmROy5gOMss+QdubKBgAAUITNBgAAUITNBgAAUESPrNnIZPfWN+/ry+7Ny+7Tp3vL7jfP7vVuZllzsM6U1QKpD+qZNm7cGLLFixeH7Mwzz6yNTz/99DAna2735JNPHsPqOiY7f37pS1+qjVevXh3mXHXVVSEbP358yJr3XGd/s1/+8pdDtmTJkpDRHprnt+wc26xtq6quqVOi62Xnv/79+4cs+4zP6jguvPDC2vhzn/tcmDN37tyQZU10s9c/44wzauNzzz03zPnkJz8ZsssuuyxkzSbUO3bsCHPamSsbAABAETYbAABAETYbAABAETYbAABAEb2mQDzTLE577bXXwpysEIje6eDBg129BHqIrFFZVjTe1GqzqnbRbJ73ox/9KMxZuHBhyGbPnh2y0aNH18arVq0Kc7Iie3+33cehQ4dCljXpzR6K8Mwzz4TMe9+9DR8+vDbOmt1ljfIWLFgQsq1bt4bs85//fG38rW99K8zJisazB12ccsopIWs+4KNfv35hTtZkOFv/7bffXhtn/5521r6fUgAAQLdmswEAABRhswEAABRhswEAABTRqwvEm10m16xZE+a88cYbx2s5QC+RFa7ed999IZs+fXpt/NRTT4U5jz32WKetq7RmwXhVVdWKFStayprF8VmXYKB7yh50ccEFF9TGw4YNC3O2bdsWsltuuSVk2fli4MCBtfHVV18d5jS7gP9/WfOBQ9nvXLduXZjz61//OmR33313yLZs2RKy7sSVDQAAoAibDQAAoAibDQAAoAibDQAAoIheUyCeFe80u4Pv2rXreC0HoCYrAGx2r3399dfDnH379hVbUztREN47ZV3Fn3322ZBln/F0b80HaWQPmMge7LN27dojvlZVVdUXv/jF2vi2224Lc84555yQjR49OmSPP/54yHbu3Fkb79ixI8zJCtx74rnOlQ0AAKAImw0AAKAImw0AAKAImw0AAKCIHlkgnhWKZcU7ze7gDzzwQJiTFRUBdLasKHDjxo1dsBLoGtkDEObNmxeypUuXhkyBePeWvX8PP/xwbfyrX/0qzHn00UdD1ur3tubDB1555ZUwJys2z7qd+6747lzZAAAAirDZAAAAirDZAAAAiuhzuMXuIX369Cm9lqKye+yamXvujt7xaj7T3Y8/yjiezY8cg2ScA8vq27dvyLJGf71Vbzr+sjX0xAZ43Umr//+ubAAAAEXYbAAAAEXYbAAAAEXYbAAAAEX0yKZ+maxhjCZAANC+FIPzP4rBuy9XNgAAgCJsNgAAgCJsNgAAgCJsNgAAgCJa7iAOAABwNFzZAAAAirDZAAAAirDZAAAAirDZAAAAirDZAAAAirDZAAAAirDZAAAAirDZAAAAirDZAAAAivg/SW061cqCssQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l', 'u', 'n', 't', 'b']\n"
     ]
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(10, 2))\n",
    "\n",
    "N = 5\n",
    "labels = []\n",
    "for i in range(1, N+1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    labels.append(train_data.classes[label])\n",
    "    figure.add_subplot(1, N, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Код для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взят из семинаров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(model,\n",
    "                   x_batch,\n",
    "                   y_batch,\n",
    "                   optimizer,\n",
    "                   loss_function):\n",
    "    \n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "\n",
    "    output = model(x_batch.to(device))\n",
    "\n",
    "    loss = loss_function(output, y_batch.to(device))\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return loss.cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_generator,\n",
    "                model,\n",
    "                loss_function,\n",
    "                optimizer,\n",
    "                callback=None):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        batch_loss = train_on_batch(model, batch_of_x.to(device), batch_of_y.to(device), optimizer, loss_function)\n",
    "\n",
    "        if callback is not None:\n",
    "            callback(model, batch_loss)\n",
    "\n",
    "        epoch_loss += batch_loss * len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "\n",
    "    return epoch_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(count_of_epoch,\n",
    "            batch_size,\n",
    "            dataset,\n",
    "            model,\n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            lr=0.001,\n",
    "            callback=None):\n",
    "\n",
    "    optima = optimizer(model.parameters(), lr=lr)\n",
    "\n",
    "    iterations = range(count_of_epoch)\n",
    "    for it in iterations:\n",
    "        batch_generator = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      shuffle=True)\n",
    "\n",
    "        epoch_loss = train_epoch(\n",
    "            train_generator=batch_generator,\n",
    "            model=model,\n",
    "            loss_function=loss_function,\n",
    "            optimizer=optima,\n",
    "            callback=callback\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_of_train(batch_size,\n",
    "                     dataset,\n",
    "                     model,\n",
    "                     loss_function):\n",
    "\n",
    "    batch_generator = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                                  batch_size=batch_size)\n",
    "\n",
    "    pred = []\n",
    "    real = []\n",
    "    test_loss = 0\n",
    "\n",
    "    for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        output = model(x_batch)\n",
    "\n",
    "        test_loss += loss_function(output, y_batch).cpu().item() * len(x_batch)\n",
    "\n",
    "        pred.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "        real.extend(y_batch.cpu().numpy().tolist())\n",
    "\n",
    "    test_loss /= len(dataset)\n",
    "\n",
    "    return test_loss, pred, real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        for p in self.parameters():\n",
    "            return p.device\n",
    "\n",
    "    def __init__(self, n_layers=1, kernel_size=5, pooling=False, batch_norm=False, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        # Number of channels in input pictures (black&white picture => 1 channel).\n",
    "        self.n_channels = 1\n",
    "        self.layers = torch.nn.Sequential()\n",
    "\n",
    "        for layer in range(n_layers):\n",
    "            # Convolution with n_channels*4 filters/kernels of size (n_channels, kernel_size, kernel_size)\n",
    "            self.layers.add_module('conv' + str(layer),\n",
    "                torch.nn.Conv2d(self.n_channels, self.n_channels * 4,\n",
    "                                kernel_size=kernel_size, padding=(kernel_size - 1) // 2))\n",
    "            self.n_channels *= 4\n",
    "\n",
    "            # Batch normalization\n",
    "            if batch_norm:\n",
    "                self.layers.add_module('bn' + str(layer), torch.nn.BatchNorm2d(self.n_channels))\n",
    "\n",
    "            self.layers.add_module('relu' + str(layer), torch.nn.ReLU())\n",
    "\n",
    "            if pooling:\n",
    "                # Pooling with kernel_size = stride\n",
    "                self.layers.add_module('pool' + str(layer), torch.nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.layers.add_module('flatten', torch.nn.Flatten(start_dim=1))\n",
    "        self.layers.add_module('dropout', torch.nn.Dropout(dropout))\n",
    "        # Use LazyLinear to automatically infer amount of in_features\n",
    "        self.layers.add_module('linear', torch.nn.LazyLinear(n_classes))\n",
    "\n",
    "        # Do not use softmax, because we use CrossEntropyLoss, which uses softmax internally.\n",
    "        # See: https://discuss.pytorch.org/t/pytorch-torch-nn-equivalent-of-tensorflow-keras-dense-layers/133518/6\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.layers(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensorboard_callback():\n",
    "    def __init__(self, writer, dataset, loss_function, batch_size, delimeter):\n",
    "        self.step = 0\n",
    "        self.writer = writer\n",
    "        self.delimeter = delimeter\n",
    "        self.loss_function = loss_function\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def forward(self, model, loss):\n",
    "        self.step += 1\n",
    "        self.writer.add_scalar('LOSS/train', loss, self.step)\n",
    "\n",
    "        if self.step % self.delimeter == 0:\n",
    "            self.writer.add_graph(model, self.dataset[0][0].view(1, 1, 28, 28).to(model.device))\n",
    "\n",
    "            test_loss, pred, real = quality_of_train(batch_size=self.batch_size, dataset=self.dataset,\n",
    "                                                     model=model, loss_function=self.loss_function)\n",
    "            self.writer.add_scalar('LOSS/test', test_loss, self.step)\n",
    "            self.writer.add_scalar('ACCURACY/test',\n",
    "                                   1 - np.count_nonzero(np.array(pred) - np.array(real)) / len(self.dataset),\n",
    "                                   self.step)\n",
    "\n",
    "    def __call__(self, model, loss):\n",
    "        return self.forward(model, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                  | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.0, 'kernel_size': 3, 'n_layers': 2, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▎                                                                                                                                     | 1/32 [00:48<25:18, 48.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.0, 'kernel_size': 3, 'n_layers': 2, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▋                                                                                                                                 | 2/32 [01:37<24:20, 48.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.0, 'kernel_size': 3, 'n_layers': 3, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████████▉                                                                                                                             | 3/32 [02:38<26:17, 54.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.0, 'kernel_size': 3, 'n_layers': 3, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████████▎                                                                                                                        | 4/32 [03:28<24:30, 52.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.0, 'kernel_size': 5, 'n_layers': 2, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████████▌                                                                                                                    | 5/32 [04:19<23:27, 52.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.0, 'kernel_size': 5, 'n_layers': 2, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████████▉                                                                                                                | 6/32 [05:07<21:57, 50.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.0, 'kernel_size': 5, 'n_layers': 3, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████████▏                                                                                                           | 7/32 [06:20<24:04, 57.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.0, 'kernel_size': 5, 'n_layers': 3, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████████████████▌                                                                                                       | 8/32 [07:11<22:16, 55.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.3, 'kernel_size': 3, 'n_layers': 2, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████████████████████▊                                                                                                   | 9/32 [08:01<20:43, 54.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.3, 'kernel_size': 3, 'n_layers': 2, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████████████████████▊                                                                                              | 10/32 [08:52<19:29, 53.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.3, 'kernel_size': 3, 'n_layers': 3, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████████████████████████                                                                                          | 11/32 [09:58<19:58, 57.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.3, 'kernel_size': 3, 'n_layers': 3, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████████████████████▍                                                                                     | 12/32 [10:52<18:39, 55.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.3, 'kernel_size': 5, 'n_layers': 2, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████████████████████████▋                                                                                 | 13/32 [11:46<17:34, 55.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.3, 'kernel_size': 5, 'n_layers': 2, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████████████████████████████▉                                                                             | 14/32 [12:38<16:20, 54.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.3, 'kernel_size': 5, 'n_layers': 3, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████████████████████████▏                                                                        | 15/32 [13:56<17:26, 61.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': False, 'dropout': 0.3, 'kernel_size': 5, 'n_layers': 3, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████████████▌                                                                    | 16/32 [14:50<15:50, 59.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.0, 'kernel_size': 3, 'n_layers': 2, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████████████████████████████████████████████████████████▊                                                                | 17/32 [15:43<14:20, 57.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.0, 'kernel_size': 3, 'n_layers': 2, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████████████████████████████████████████                                                            | 18/32 [16:36<13:03, 55.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.0, 'kernel_size': 3, 'n_layers': 3, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████████████████████████████████████████████▎                                                       | 19/32 [17:44<12:56, 59.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.0, 'kernel_size': 3, 'n_layers': 3, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████████████████████████████████████████▋                                                   | 20/32 [18:39<11:40, 58.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.0, 'kernel_size': 5, 'n_layers': 2, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████████████████████████████████████▉                                               | 21/32 [19:35<10:34, 57.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.0, 'kernel_size': 5, 'n_layers': 2, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 22/32 [20:29<09:23, 56.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.0, 'kernel_size': 5, 'n_layers': 3, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 23/32 [21:51<09:36, 64.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.0, 'kernel_size': 5, 'n_layers': 3, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 24/32 [22:47<08:14, 61.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.3, 'kernel_size': 3, 'n_layers': 2, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 25/32 [23:42<06:57, 59.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.3, 'kernel_size': 3, 'n_layers': 2, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 26/32 [24:35<05:46, 57.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.3, 'kernel_size': 3, 'n_layers': 3, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 27/32 [25:45<05:06, 61.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.3, 'kernel_size': 3, 'n_layers': 3, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                 | 28/32 [26:41<03:58, 59.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.3, 'kernel_size': 5, 'n_layers': 2, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 29/32 [27:38<02:56, 58.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.3, 'kernel_size': 5, 'n_layers': 2, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 30/32 [28:31<01:54, 57.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.3, 'kernel_size': 5, 'n_layers': 3, 'pooling': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 31/32 [29:54<01:04, 64.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_norm': True, 'dropout': 0.3, 'kernel_size': 5, 'n_layers': 3, 'pooling': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [30:51<00:00, 57.85s/it]\n"
     ]
    }
   ],
   "source": [
    "grid = ParameterGrid({\n",
    "    'n_layers': [2, 3],\n",
    "    'kernel_size': [3, 5],\n",
    "    'pooling': [False, True],\n",
    "    'batch_norm': [False, True],\n",
    "    'dropout': [0.0, 0.3],\n",
    "})\n",
    "\n",
    "for params in tqdm(grid):\n",
    "    print(str(params))\n",
    "\n",
    "    # Create model\n",
    "    model = CNN(**params)\n",
    "    mod = model.to(device)\n",
    "    \n",
    "    writer = SummaryWriter(f'experiments/{str(params)}')\n",
    "    callback = tensorboard_callback(writer, test_data, loss_function, batch_size=batch_size, delimeter=300)\n",
    "\n",
    "    trainer(count_of_epoch=3,\n",
    "            batch_size=batch_size,\n",
    "            dataset=train_data,\n",
    "            model=model,\n",
    "            loss_function=loss_function,\n",
    "            optimizer=optimizer,\n",
    "            lr=0.001,\n",
    "            callback=callback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализована модель CNN, проведен grid-search по гиперпараметрам, выполнена оценка loss и accuracy.\n",
    "\n",
    "Результаты:\n",
    "- Модели с 3 слоями лучше, чем с двумя, при фиксации остальных параметров.\n",
    "- Pooling ухудшает качество модели\n",
    "- Batch norm ухудшает качество модели\n",
    "- Dropout ухудшает качество модели\n",
    "- Небольшая разница в качестве между train/test\n",
    "\n",
    "Все результаты говорят о том, что модели не хватает гибкости. Можно попробовать увеличить количество слоев, размер kernel-a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Обучение занимает значительный период времени (порядка 40-60 секунд для каждой конфигурации гиперпараметров на consumer-grade PC). Значительный overhead дает расчет loss/accuracy на test_data для tensorboard-a, поэтому параметр delimeter (раз во сколько batch-ей производится расчет) был поднят с 10 до 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
